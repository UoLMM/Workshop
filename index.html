<!doctype html>
<html lang="en-US">
<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width,initial-scale=1.0"/>
<title>Robust Understanding of Low-quality Multimedia Data: Unitive Enhancement, Analysis, and Evaluation(UoLMM)</title>
 <meta name="description" content="Website for Robust Understanding of Low-quality Multimedia Data: Unitive Enhancement, Analysis, and Evaluation ---">
<link href="css/singlePageTemplate.css" rel="stylesheet" type="text/css">
<!--The following script tag downloads a font from the Adobe Edge Web Fonts server for use within the web page. We recommend that you do not modify it.-->
<script>var __adobewebfontsappname__="dreamweaver"</script>
<script src="http://use.edgefonts.net/source-sans-pro:n2:default.js" type="text/javascript"></script>
<!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
<!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
<!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>
<body>
<!-- Main Container -->

<div class="container"> 
  <!-- Navigation -->
  <header class="header" ><img class="mmimg" src="images/MMpage2.png" />
    <nav>
      <ul>
        <li><a href="#homepage">Home</a></li>
        <li><a href="#call4paper">Call for Papers</a></li>
        <li><a href="#submission">Submission</a></li>
        <li> <a href="#dates">Important Dates</a></li>
        <li> <a href="#speakers">Speakers</a></li>
        <li> <a href="#organizers">Organizers</a></li>
      </ul>
    </nav>
</header>

	  <section id="homepage2">
<div align ="center"  style="position: relative; width: 100%;">
<img align ="center" class="pic" src="images/Bg-Pic3.jpg" alt="">
  <div class = "title" ><strong>The 2nd International Workshop On Robust Understanding of Low-quality Multimedia Data</strong></div>
  <div class = "subtitle" ><strong>Unitive Enhancement, Analysis, and Evaluation (UoLMM)</strong></div>

    <div class = "title2" ><strong>In Conjunction with <a href="https://2022.acmmm.org/" class="link" target="_blank">ACM MM 2022</a></strong></div>
    <div class = "title3" ><strong>Lisbon, Portugal | 10-14 October</strong></div>
</div> 
</section>

  <section id="homepage">
<div class="stats">
  <h1><strong>Introduction</strong></h1>
</div>
<div class="stats_text">
    <p>Low-quality multimedia data (including low-resolution, low-illumination, defects, blurriness, <i>etc</i>.) often pose a challenge to content understanding, as algorithms are mainly developed under ideal conditions (high resolution and good visibility). To alleviate this problem, data enhancement techniques (super-resolution, low-light enhancement, derain, and inpainting) have been proposed to restore low-quality multimedia data. Efforts are also being made to develop robust content understanding algorithms in adverse weather and poor lighting conditions. Some quality assessment techniques aimed at evaluating the analytical quality of data have also emerged. Even though these topics are mostly studied independently, they are tightly related in terms of ensuring a robust understanding of multimedia content. For example, enhancement should maintain the semantic consistency in analysis, while quality assessment should take into account the comprehensibility of multimedia data.
</p>
    <p>This workshop aims to bring together individuals in three topics of enhancement, analysis, and evaluation of low-quality multimedia data for sharing ideas and discussion on current developments and future directions. 
</p>
</div>
</section>

  <section id="call4paper">
<div class="stats">
    <h1><strong>Call for Papers</strong></h1>
</div>
<div class="stats_text">
    <p>
      The main goal of this workshop is to bring together leading experts from academia and industry in the three fields of multimedia data enhancement, multimedia content analysis, and quality evaluation for sharing ideas and discussions on current trends, developments, issues, and future directions, with the vision of bridging the three fields for a robust understanding of the low-quality data in the broader context of multimedia applications. 
      The topics may include but are not limited to:
    </p>
    <ul class="stats_text_ul">
      <li>Emerging trends in data enhancement, analysis, or evaluation</li>
      <li>Enhancement for the robust content understanding of low-quality data</li>
      <li>Quality evaluation for the robust content understanding of low-quality data</li>
      <li>Assessment-guided visual content enhancement of low-quality data</li>
      <li>Joint embeddings learning for enhancement, analysis, and evaluation </li>
      <li>Real-world systems and applications</li>
    </ul>
</div>
</section>

<section id="submission">
<div class="stats">
    <h1><strong>Paper Submission</strong></h1>
</div>

<div class="stats_text">
	<p>OpenReview website: <a href="https://openreview.net/group?id=acmmm.org/ACMMM/2022/Workshop/UoLMM" class="link" target="_blank">https://openreview.net/group?id=acmmm.org/ACMMM/2022/Workshop/UoLMM</a></p>
    <p>After signing in the ACM MM 2022 submission site as the author, please choose our workshop name to submit the paper. Submissions can be of varying length from 4 to 8 pages, plus additional pages for the reference pages; i.e., the reference page(s) are not counted to the page limit of 4 to 8 pages. There is no distinction between long and short papers, but the authors may themselves decide on the appropriate length of the paper.. All papers will be peer-reviewed by experts in the field, they will receive at least three reviews. Acceptance will be based on relevance to the workshop, scientific novelty, and technical quality. The workshop papers will be published in the ACM Digital Library.</p>
<p>Please refer to the main conference site for submission policies on blinding, originality, author lists and ArXiv publications.</p>
</div>

</section>

<section id="dates">
<div class="stats">
    <h1><strong>Important Dates</strong></h1>
</div>

<div class="stats_text">
    <ul  class="stats_text_ul">
      <li>Paper submission deadline: &nbsp&nbsp <s><strong>1st July 2022</strong></s>&nbsp<strong>10th July 2022</strong></li>
      <li>Notification of acceptance: &nbsp&nbsp&nbsp&nbsp <strong>29th July 2022</strong></li>
      <li>Camera ready submission: &nbsp&nbsp&nbsp&nbsp <strong>14th August 2022</strong></li>
	<li>Workshop Date (Hybrid): &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp <strong>14 October 2022</strong></li>
    </ul>
</div>
</section>

<section id="speakers">
	  <div class="stats">
    <h1><strong>Keynote Speakers</strong></h1>
  </div>
<table class="imgtable"><tr><td>
<img class="speaker-pic" src="images/Speakers-Wenjun Z.jpg" /> 
	<br /> 
    <p class="people-name-name"><a  href="https://scholar.google.com/citations?user=_cUfvYQAAAAJ&hl=zh-CN/"  class="link" target="_blank">Prof. Wenjun Zeng</a></p>
    <p class="people-name-inner">IEEE Fellow</p>
    <p class="people-name-outer">EIT Institute for Advanced Study</p>
	</td>
<td valign="top">
<p class="speaker_title"> Title: Unlocking the Potential of Disentangled Representation for Robust Media Understanding </p>
<p class="speaker_text">
	<strong><i>Abstract</i></strong>: It has been argued that for AI to fundamentally understand the world around us, it must learn to identify and disentangle the underlying explanatory factors hidden in the observed environment of low-level sensory data. In this talk, I will first provide an overview of the recent developments in disentangled representation learning and identify some major trends.  I will then present some applications of this powerful concept for robust media processing and understanding in tasks such as image restoration, super-resolution, classification, person re-ID, depth estimation, etc.  I will also discuss some future directions.
<br />
<br />
	<strong><i>Biography</i></strong>: Prof. Wenjun (Kevin) Zeng has been a Chair Professor and Vice President for Research of the Eastern Institute for Advanced Study, Ningbo, China since Oct. 2021. Prior to that, he was a Sr. Principal Research Manager and a member of the Senior Leadership Team at Microsoft Research Asia where He was leading the video analytics research powering the Microsoft Cognitive Services, Azure Media Analytics Services, Microsoft Office, Dynamics, and Windows Machine Learning. He was with the Computer Science Dept. of Univ. of Missouri from 2003 to 2016, most recently as a Full Professor. Prior to that, he worked for PacketVideo Corp, San Diego, CA, Sharp Labs of America, Camas, WA, Bell Labs, Murray Hill, NJ, and Panasonic Technology, Princeton, NJ. He has contributed significantly to the development of international standards (ISO MPEG, JPEG2000, and Open Mobile Alliance). He received his B.E., M.S., and Ph.D. degrees from Tsinghua Univ., the Univ. of Notre Dame, and Princeton Univ., respectively. He is on the Editorial Board of International Journal of Computer Vision, and was an Associate Editor-in-Chief, Associate Editor, or Steering Committee members for a number of IEEE journals. He has served as the General Chair or TPC Chair for several IEEE Conferences (e.g., ICME’2018, ICIP’2017). He is a Fellow of the IEEE. 
 </p>
</td></tr>
	<tr><td><br /><br /><br /><br /></td><td><br /><br /><br /><br /></td></tr>
<tr><td>
	
<img class="speaker-pic" src="images/Speakers-Weisi L.jpg" /> 
	<br /> 
      <p class="people-name-name"><a  href="https://personal.ntu.edu.sg/wslin/"  class="link" target="_blank">Prof. Weisi Lin</a></p>
      <p class="people-name-inner">IEEE Fellow</p>
      <p class="people-name-outer">Nanyang Technological University</p>
	</td>
<td valign="top">
<p class="speaker_title"> Title: Visual Signal Assessment, Analysis and Enhancement for Low-resolution or Varying-illumination Environment </p>
<p class="speaker_text">
	<strong><i>Abstract</i></strong>: More often than not, practical application scenarios call for systems to be capable of dealing with input visual signals with low resolution/quality or environmental illumination. This talk will introduce related recent research in super-resolution reconstruction, signal quality assessment, content enhancement, and person re-identification for low-resolution or varying illumination. We will also discuss possible new research attempts to advance the relevant techniques.
<br />
<br />
	<strong><i>Biography</i></strong>: Prof. Weisi Lin received the Ph.D. degree from King’s College, London University, U.K. He is currently a Professor with the School of Computer Science and Engineering, Nanyang Technological University. His areas of expertise include image processing, perceptual signal modeling, video compression, and multimedia communication, in which he has published over 200 journal papers, over 230 conference papers, filed seven patents, and authored two books. He has been an invited/panelist/keynote/tutorial speaker in over 20 international conferences, as well as a Distinguished Lecturer of the IEEE Circuits and Systems Society (2016–2017), and the Asia-Pacific Signal and Information Processing Association (APSIPA) (2012–2013). He is a Fellow of the IET, and an Honorary Fellow of Singapore Institute of Engineering Technologists. He has been a Technical Program Chair for IEEE ICME 2013, PCM 2012, QoMEX 2014, and IEEE VCIP 2017. He has been an Associate Editor for the IEEE Transactions on Image Processing, the IEEE Transactions on Circuits and Systems for Video Technology, the IEEE Transactions on Multimedia, and the IEEE Signal Processing Letters. He is a Fellow of the IEEE.
 </p>
</td></tr>
<tr><td>
    <img class="speaker-pic" src="images/Speakers-Jinwei G.png" />
	<br /> 
      <p class="people-name-name"><a  href="https://www.gujinwei.org/"  class="link" target="_blank">Dr. Jinwei Gu</a></p>
      <p class="people-name-inner">Executive R&D Director</p>
      <p class="people-name-outer">SenseBrain</p>
	</td>
<td valign="top"><br /><br /><br />
<p class="speaker_title"> Title: Computational Imaging on Mobile Phones </p>
<p class="speaker_text">
	<strong><i>Abstract</i></strong>: Computational imaging refers to sensing the real world with optimally designed, task-specific, multi-modality image sensors and optics which actively probes key visual information. Together with advances in AI algorithms and powerful hardware, computational imaging has significantly improved the image and video quality of mobile phones in many aspects, which not only benefits computer vision tasks but also results in novel hardware, such as AI image sensors, AI ISP (Image Signal Processing) chips, and AI camera systems. In this talk, I will present several latest research results including high quality image restoration and accurate depth estimation from time-of-flight sensors or monocular videos, as well as some latest computational photography products in smart phones including under-display cameras, AI image sensors and AI ISP chips. I will also layout several open challenges and future research directions in this area.
<br />
<br />
	<strong><i>Biography</i></strong>: Dr. Jinwei Gu is the R&D Executive Director of SenseBrain (aka SenseTime USA). His current research focuses on low-level computer vision, computational photography, computational imaging, smart visual sensing and perception, and appearance modeling. He obtained his Ph.D. degree in 2010 from Columbia University, and his B.S and M.S. from Tsinghua University, in 2002 and 2005 respectively. Before joining SenseTime, he was a senior research scientist in NVIDIA Research from 2015 to 2018.  Prior to that, he was an assistant professor in Rochester Institute of Technology from 2010 to 2013, and a senior researcher in the media lab of Futurewei Technologies from 2013 to 2015. He serves as an associate editor for IEEE Transactions on Computational Imaging (TCI) and IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), an area chair for ICCV2019, ECCV2020, and CVPR2021, and industry chair for ICCP2020.  He is an IEEE senior member since 2018. His research work has been successfully transferred to many products such as NVIDIA CoPilot SDK, DriveIX SDK, as well as super resolution, super night, portrait restoration, RGBW solution which are widely used in many flagship mobile phones. 
 </p>
</td></tr>	
	</table>	
	
</section>


<section id="organizers">
  <div class="stats">
    <h1><strong>Workshop Organizers</strong></h1>
  </div>
<div class="text-center_organizer">
  <div class="col-xs-2">
      <img class="people-pic" src="images/people_LiangLiao.png" />
    <div class="people-name">
<p class="people-name-name"><a href="https://liaoliang92.github.io/homepage/" class="link" target="_blank">Dr. Liang Liao</a></p>      <p class="people-name-inner">liang.liao AT ntu.edu.sg</p>
      <p class="people-name-outer">NTU, Singapore</p>
    </div>
  </div>

  <div class="col-xs-2">

    <img class="people-pic" src="images/Dan Xu.jpg" />
  <div class="people-name">
    <p class="people-name-name"><a  href="https://www.danxurgb.net/"  class="link" target="_blank">Dr. Dan Xu</a></p>
	  <p class="people-name-inner">danxu AT cse.ust.hk</p>
    <p class="people-name-outer">HKUST, HongKong, China</p>
  </div>
  </div>

  <div class="col-xs-2">

    <img class="people-pic" src="images/Yang Wu.jpg" />
  <div class="people-name">
    <p class="people-name-name"><a  href="https://scholar.google.com.hk/citations?user=vwOQ-UIAAAAJ&hl=zh-CN"  class="link" target="_blank">Dr. Yang Wu</a></p>
	  <p class="people-name-inner">dylanywu AT tencent.com</p>
    <p class="people-name-outer">Tencent, China</p>
  </div>
  </div>

  <div class="col-xs-2">

      <img class="people-pic" src="images/people_XiaoWang.png" />
    <div class="people-name">
      <p class="people-name-name"><a  href="https://www.wust.edu.cn/jsjenglish/2021/0723/c6412a242998/page.htm"  class="link" target="_blank">Dr. Xiao Wang</a></p>
	    <p class="people-name-inner">wangxiao2021 AT wust.edu.cn</p>
      <p class="people-name-outer">WUST, China</p>
    </div>
  </div>

  <div class="col-xs-2">

      <img class="people-pic" src="images/people_JingXiao.png" />
    <div class="people-name">
      <p class="people-name-name"><a  href="https://scholar.google.com/citations?user=RXBiwbUAAAAJ&hl=zh-CN"  class="link" target="_blank">Dr. Jing Xiao</a></p>
	    <p class="people-name-inner">jing AT whu.edu.cn</p>
      <p class="people-name-outer">WHU, China</p>
    </div>
  </div>
</div>

</section>
</div>
  <footer class="secondary_header footer">
<div class="copyright">&nbsp</div>
    <div class="copyright">&copy;2022 - <strong>ACM MM Workshop - UoLMM</strong></div>
<div class="copyright">&nbsp</div>
  </footer>
</body>

</html>
